{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here, choose embeddings file:"
      ],
      "metadata": {
        "id": "J1h0aQdQhbHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.load(\"homo_gly_embeddings_X.npy\")\n",
        "#x = np.load(\"homo_cro_embeddings_X.npy\")\n",
        "#x = np.load(\"homo_ubi_embeddings_X.npy\")\n",
        "#x = np.load(\"yeast_suc_embeddings_X.npy\")\n",
        "#x = np.load(\"mouse_suc_embeddings_X.npy\")\n",
        "#x = np.load(\"homo_suc_embeddings_X.npy\")"
      ],
      "metadata": {
        "id": "XRmiQ7J0LIE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "nynTSqADLIR3",
        "outputId": "fe8b580f-3083-4820-93ce-5f2a6f2da9f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6684, 17664)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, choose label file:"
      ],
      "metadata": {
        "id": "4hBmCAMwhj_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.load(\"homo_gly_embeddings_Y.npy\")\n",
        "#y = np.load(\"homo_cro_embeddings_Y.npy\")\n",
        "#y = np.load(\"homo_ubi_embeddings_Y.npy\")\n",
        "#y = np.load(\"yeast_suc_embeddings_Y.npy\")\n",
        "#y = np.load(\"mouse_suc_embeddings_Y.npy\")\n",
        "#y = np.load(\"homo_suc_embeddings_Y.npy\")"
      ],
      "metadata": {
        "id": "LiqYjD-qLXB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-w9lGOkk_nA",
        "outputId": "1afa12fa-acd2-46d6-c522-5555a36e694d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6684,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "x_dataframe = pd.DataFrame(x)"
      ],
      "metadata": {
        "id": "wkyDmq8Kyl2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "A7L45Ff2y_4f",
        "outputId": "1cc9310f-c5d4-4a67-aad4-dde0944cdd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6      \\\n",
              "0    -0.670064 -0.205453 -0.162788  0.238185 -0.497634  0.001058  0.498252   \n",
              "1     0.148248  0.410427 -0.160469 -0.907297 -0.426901 -0.446572  0.441898   \n",
              "2    -0.672000 -0.157473 -0.155070 -0.118049 -0.484512 -0.128078  0.507044   \n",
              "3    -0.132867  0.849208 -0.978939 -1.040755 -1.157435 -0.268314  0.898318   \n",
              "4    -0.873999 -0.313660 -0.237740 -0.002625 -0.309743 -0.102321  0.587243   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "6679  0.170743  0.856997 -1.132284 -1.372333 -0.804080 -0.158089  0.788468   \n",
              "6680 -0.569732 -0.155709 -0.136024 -0.149933 -0.446000 -0.081807  0.493711   \n",
              "6681  0.278941  0.867220 -0.684302 -0.722783 -1.062452 -0.475852  1.015704   \n",
              "6682 -0.824142 -0.163899 -0.147529  0.011811 -0.260180 -0.011521  0.452661   \n",
              "6683 -0.334936  0.528799 -0.690188 -1.078601 -0.826804  0.050996  0.694527   \n",
              "\n",
              "         7         8         9      ...     17654     17655     17656  \\\n",
              "0     0.217543 -0.204923 -0.193458  ...  0.058214 -0.014467 -0.196105   \n",
              "1    -0.929678 -0.320961 -0.327232  ... -0.008504 -0.048857 -0.160131   \n",
              "2     0.094098 -0.129200 -0.446905  ...  0.039919  0.031626 -0.210442   \n",
              "3    -0.550852 -0.409919  0.014149  ... -0.099752  0.204240  0.072771   \n",
              "4     0.325927 -0.265885 -0.335534  ...  0.081942  0.022739 -0.189747   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "6679 -0.143002  0.390288 -0.043355  ... -0.203046  0.406106  0.083288   \n",
              "6680  0.192582 -0.186166 -0.485428  ...  0.033619  0.008939 -0.172864   \n",
              "6681  0.254639 -0.553932 -0.933954  ...  0.177753  0.125788  0.013824   \n",
              "6682  0.303969 -0.217640 -0.423763  ...  0.083240  0.032962 -0.220289   \n",
              "6683 -0.745586 -0.203401  0.739010  ... -0.193964  0.105839  0.005511   \n",
              "\n",
              "         17657     17658     17659     17660     17661     17662     17663  \n",
              "0    -0.225642  0.041844 -0.069661 -0.033239  0.054932 -0.228640 -0.068469  \n",
              "1     0.005937  0.464745 -0.093560 -0.289759  0.168618 -0.303013  0.615383  \n",
              "2    -0.186345  0.045548 -0.049786  0.021884  0.049393 -0.225488 -0.053107  \n",
              "3    -0.050610  1.097281 -0.049464 -0.439880  0.144016 -0.291581  0.844872  \n",
              "4    -0.220977  0.046227 -0.086532 -0.019842  0.043630 -0.247233 -0.055414  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "6679 -0.140104  0.904826 -0.279064 -0.489204  0.250356  0.116384  0.886395  \n",
              "6680 -0.249434  0.026223 -0.062253 -0.006292  0.037104 -0.267372 -0.058867  \n",
              "6681  0.191988  0.426629 -0.601371 -0.308372 -0.044944  0.065832  0.249223  \n",
              "6682 -0.211165  0.047671 -0.052222  0.028940  0.060261 -0.230897 -0.042840  \n",
              "6683  0.004623  0.520290 -0.119483 -0.317003  0.230785 -0.392739  0.740903  \n",
              "\n",
              "[6684 rows x 17664 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2d16c5d-c184-4984-b577-3bf0225d5fc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>17654</th>\n",
              "      <th>17655</th>\n",
              "      <th>17656</th>\n",
              "      <th>17657</th>\n",
              "      <th>17658</th>\n",
              "      <th>17659</th>\n",
              "      <th>17660</th>\n",
              "      <th>17661</th>\n",
              "      <th>17662</th>\n",
              "      <th>17663</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.670064</td>\n",
              "      <td>-0.205453</td>\n",
              "      <td>-0.162788</td>\n",
              "      <td>0.238185</td>\n",
              "      <td>-0.497634</td>\n",
              "      <td>0.001058</td>\n",
              "      <td>0.498252</td>\n",
              "      <td>0.217543</td>\n",
              "      <td>-0.204923</td>\n",
              "      <td>-0.193458</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058214</td>\n",
              "      <td>-0.014467</td>\n",
              "      <td>-0.196105</td>\n",
              "      <td>-0.225642</td>\n",
              "      <td>0.041844</td>\n",
              "      <td>-0.069661</td>\n",
              "      <td>-0.033239</td>\n",
              "      <td>0.054932</td>\n",
              "      <td>-0.228640</td>\n",
              "      <td>-0.068469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.148248</td>\n",
              "      <td>0.410427</td>\n",
              "      <td>-0.160469</td>\n",
              "      <td>-0.907297</td>\n",
              "      <td>-0.426901</td>\n",
              "      <td>-0.446572</td>\n",
              "      <td>0.441898</td>\n",
              "      <td>-0.929678</td>\n",
              "      <td>-0.320961</td>\n",
              "      <td>-0.327232</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008504</td>\n",
              "      <td>-0.048857</td>\n",
              "      <td>-0.160131</td>\n",
              "      <td>0.005937</td>\n",
              "      <td>0.464745</td>\n",
              "      <td>-0.093560</td>\n",
              "      <td>-0.289759</td>\n",
              "      <td>0.168618</td>\n",
              "      <td>-0.303013</td>\n",
              "      <td>0.615383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.672000</td>\n",
              "      <td>-0.157473</td>\n",
              "      <td>-0.155070</td>\n",
              "      <td>-0.118049</td>\n",
              "      <td>-0.484512</td>\n",
              "      <td>-0.128078</td>\n",
              "      <td>0.507044</td>\n",
              "      <td>0.094098</td>\n",
              "      <td>-0.129200</td>\n",
              "      <td>-0.446905</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039919</td>\n",
              "      <td>0.031626</td>\n",
              "      <td>-0.210442</td>\n",
              "      <td>-0.186345</td>\n",
              "      <td>0.045548</td>\n",
              "      <td>-0.049786</td>\n",
              "      <td>0.021884</td>\n",
              "      <td>0.049393</td>\n",
              "      <td>-0.225488</td>\n",
              "      <td>-0.053107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.132867</td>\n",
              "      <td>0.849208</td>\n",
              "      <td>-0.978939</td>\n",
              "      <td>-1.040755</td>\n",
              "      <td>-1.157435</td>\n",
              "      <td>-0.268314</td>\n",
              "      <td>0.898318</td>\n",
              "      <td>-0.550852</td>\n",
              "      <td>-0.409919</td>\n",
              "      <td>0.014149</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099752</td>\n",
              "      <td>0.204240</td>\n",
              "      <td>0.072771</td>\n",
              "      <td>-0.050610</td>\n",
              "      <td>1.097281</td>\n",
              "      <td>-0.049464</td>\n",
              "      <td>-0.439880</td>\n",
              "      <td>0.144016</td>\n",
              "      <td>-0.291581</td>\n",
              "      <td>0.844872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.873999</td>\n",
              "      <td>-0.313660</td>\n",
              "      <td>-0.237740</td>\n",
              "      <td>-0.002625</td>\n",
              "      <td>-0.309743</td>\n",
              "      <td>-0.102321</td>\n",
              "      <td>0.587243</td>\n",
              "      <td>0.325927</td>\n",
              "      <td>-0.265885</td>\n",
              "      <td>-0.335534</td>\n",
              "      <td>...</td>\n",
              "      <td>0.081942</td>\n",
              "      <td>0.022739</td>\n",
              "      <td>-0.189747</td>\n",
              "      <td>-0.220977</td>\n",
              "      <td>0.046227</td>\n",
              "      <td>-0.086532</td>\n",
              "      <td>-0.019842</td>\n",
              "      <td>0.043630</td>\n",
              "      <td>-0.247233</td>\n",
              "      <td>-0.055414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6679</th>\n",
              "      <td>0.170743</td>\n",
              "      <td>0.856997</td>\n",
              "      <td>-1.132284</td>\n",
              "      <td>-1.372333</td>\n",
              "      <td>-0.804080</td>\n",
              "      <td>-0.158089</td>\n",
              "      <td>0.788468</td>\n",
              "      <td>-0.143002</td>\n",
              "      <td>0.390288</td>\n",
              "      <td>-0.043355</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.203046</td>\n",
              "      <td>0.406106</td>\n",
              "      <td>0.083288</td>\n",
              "      <td>-0.140104</td>\n",
              "      <td>0.904826</td>\n",
              "      <td>-0.279064</td>\n",
              "      <td>-0.489204</td>\n",
              "      <td>0.250356</td>\n",
              "      <td>0.116384</td>\n",
              "      <td>0.886395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6680</th>\n",
              "      <td>-0.569732</td>\n",
              "      <td>-0.155709</td>\n",
              "      <td>-0.136024</td>\n",
              "      <td>-0.149933</td>\n",
              "      <td>-0.446000</td>\n",
              "      <td>-0.081807</td>\n",
              "      <td>0.493711</td>\n",
              "      <td>0.192582</td>\n",
              "      <td>-0.186166</td>\n",
              "      <td>-0.485428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033619</td>\n",
              "      <td>0.008939</td>\n",
              "      <td>-0.172864</td>\n",
              "      <td>-0.249434</td>\n",
              "      <td>0.026223</td>\n",
              "      <td>-0.062253</td>\n",
              "      <td>-0.006292</td>\n",
              "      <td>0.037104</td>\n",
              "      <td>-0.267372</td>\n",
              "      <td>-0.058867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6681</th>\n",
              "      <td>0.278941</td>\n",
              "      <td>0.867220</td>\n",
              "      <td>-0.684302</td>\n",
              "      <td>-0.722783</td>\n",
              "      <td>-1.062452</td>\n",
              "      <td>-0.475852</td>\n",
              "      <td>1.015704</td>\n",
              "      <td>0.254639</td>\n",
              "      <td>-0.553932</td>\n",
              "      <td>-0.933954</td>\n",
              "      <td>...</td>\n",
              "      <td>0.177753</td>\n",
              "      <td>0.125788</td>\n",
              "      <td>0.013824</td>\n",
              "      <td>0.191988</td>\n",
              "      <td>0.426629</td>\n",
              "      <td>-0.601371</td>\n",
              "      <td>-0.308372</td>\n",
              "      <td>-0.044944</td>\n",
              "      <td>0.065832</td>\n",
              "      <td>0.249223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6682</th>\n",
              "      <td>-0.824142</td>\n",
              "      <td>-0.163899</td>\n",
              "      <td>-0.147529</td>\n",
              "      <td>0.011811</td>\n",
              "      <td>-0.260180</td>\n",
              "      <td>-0.011521</td>\n",
              "      <td>0.452661</td>\n",
              "      <td>0.303969</td>\n",
              "      <td>-0.217640</td>\n",
              "      <td>-0.423763</td>\n",
              "      <td>...</td>\n",
              "      <td>0.083240</td>\n",
              "      <td>0.032962</td>\n",
              "      <td>-0.220289</td>\n",
              "      <td>-0.211165</td>\n",
              "      <td>0.047671</td>\n",
              "      <td>-0.052222</td>\n",
              "      <td>0.028940</td>\n",
              "      <td>0.060261</td>\n",
              "      <td>-0.230897</td>\n",
              "      <td>-0.042840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6683</th>\n",
              "      <td>-0.334936</td>\n",
              "      <td>0.528799</td>\n",
              "      <td>-0.690188</td>\n",
              "      <td>-1.078601</td>\n",
              "      <td>-0.826804</td>\n",
              "      <td>0.050996</td>\n",
              "      <td>0.694527</td>\n",
              "      <td>-0.745586</td>\n",
              "      <td>-0.203401</td>\n",
              "      <td>0.739010</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.193964</td>\n",
              "      <td>0.105839</td>\n",
              "      <td>0.005511</td>\n",
              "      <td>0.004623</td>\n",
              "      <td>0.520290</td>\n",
              "      <td>-0.119483</td>\n",
              "      <td>-0.317003</td>\n",
              "      <td>0.230785</td>\n",
              "      <td>-0.392739</td>\n",
              "      <td>0.740903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6684 rows × 17664 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2d16c5d-c184-4984-b577-3bf0225d5fc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2d16c5d-c184-4984-b577-3bf0225d5fc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2d16c5d-c184-4984-b577-3bf0225d5fc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJswL9-OzNhz",
        "outputId": "24f69f9e-9581-4c99-a19a-1a556360d3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1D CNN"
      ],
      "metadata": {
        "id": "KlPVGWWyUpuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv1D, ZeroPadding1D, MaxPooling1D, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from kerastuner import RandomSearch\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
        "xval, xtest, yval, ytest = train_test_split(xtest, ytest, test_size = 0.5)\n",
        "\n",
        "def CNN_1D():\n",
        "    model = Sequential()\n",
        "\n",
        "    # layer 1\n",
        "    model.add(Conv1D(8, 4, input_shape=(23*768, 1), activation=\"relu\"))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    # layer 2\n",
        "    model.add(Conv1D(8, 2, activation=\"relu\"))\n",
        "    model.add(MaxPooling1D(2))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Flattening Layer:\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "\n",
        "    # Last Layer:\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr = 0.00005),\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "    return model\n",
        "\n",
        "model1 = CNN_1D()\n",
        "\n",
        "a = np.asarray(xtrain).reshape(len(np.asarray(xtrain)),23*768,1)\n",
        "\n",
        "history1_ = model1.fit(np.asarray(xtrain).reshape(len(np.asarray(xtrain)),23*768,1), utils.to_categorical(ytrain,2),\n",
        "                    validation_data=(np.asarray(xval).reshape(len(np.asarray(xval)),23*768,1), utils.to_categorical(yval,2)),\n",
        "                    epochs=50, batch_size=20, verbose=1)\n",
        "\n",
        "score = model1.evaluate(np.asarray(xtest).reshape(len(np.asarray(xtest)),23*768,1), utils.to_categorical(ytest,2), verbose=1)\n",
        "print(\"categorical_crossentropy loss, Accuracy, Precision, Recall scores:\", score)\n",
        "\n",
        "\n",
        "plt.plot(history1_.history[\"accuracy\"])\n",
        "plt.plot(history1_.history[\"val_accuracy\"])\n",
        "plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "plt.ylabel(\"True positive rate\", fontsize = 15)\n",
        "plt.title(\"1D CNN Model Accuracy\", fontsize = 20)\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\",  prop={\"size\": 15})\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,10), dpi = 600)\n",
        "\n",
        "plt.plot(history1_.history[\"loss\"])\n",
        "plt.plot(history1_.history[\"val_loss\"])\n",
        "plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "plt.ylabel(\"Loss\", fontsize = 15)\n",
        "plt.title(\"1D CNN Model Loss\", fontsize = 20)\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\",  prop={\"size\": 15})\n",
        "plt.show()\n",
        "\n",
        "print(model1.summary())\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cnn_predictions1 = model1.predict(xtest)\n",
        "bert2_probs_cnn1 = cnn_predictions1[:,1]\n",
        "cnn_predictions1 = np.argmax(cnn_predictions1, axis = 1)\n",
        "confusion_matrix = confusion_matrix(ytest, cnn_predictions1)\n",
        "sns.heatmap(confusion_matrix, annot = True, fmt = \"d\", cbar = False)\n",
        "plt.title(\"BERT + 1D CNN Confusion Matrix\", fontsize = 20)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr_keras_bert_cnn1_hyp, tpr_keras_bert_cnn1_hyp, _ = roc_curve(ytest, bert2_probs_cnn1)\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "auc_keras_bert_cnn1_hyp = auc(fpr_keras_bert_cnn1_hyp, tpr_keras_bert_cnn1_hyp)\n",
        "print(\"AUC Score\", auc_keras_bert_cnn1_hyp)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras_bert_cnn1_hyp, tpr_keras_bert_cnn1_hyp, label=\"BERT + 1D-CNN: {:.3f}\".format(auc_keras_bert_cnn1_hyp))\n",
        "plt.xlabel(\"False positive rate\", fontsize = 15)\n",
        "plt.ylabel(\"True positive rate\", fontsize = 15)\n",
        "plt.title(\"ROC curve for BERT + 1D CNN\", fontsize = 20)\n",
        "plt.legend(loc=\"best\",  prop={'size': 15})\n",
        "plt.show()\n",
        "\n",
        "print(\"----------------------------------------------\")\n",
        "\n",
        "\n",
        "precision_bert2_cnn1, recall_bert2_cnn1, _ = precision_recall_curve(ytest, bert2_probs_cnn1)\n",
        "auc_precision_recall_bert2_cnn1 = auc(recall_bert2_cnn1, precision_bert2_cnn1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(recall_bert2_cnn1, precision_bert2_cnn1, label=\"BERT + 1D-CNN: {:.3f}\".format(auc_precision_recall_bert2_cnn1))\n",
        "plt.xlabel(\"Recall\", fontsize = 15)\n",
        "plt.ylabel(\"Precision\", fontsize = 15)\n",
        "plt.title(\"PR curve for BERT + 1D CNN\", fontsize = 20)\n",
        "plt.legend(loc=\"best\",  prop={'size': 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------\")"
      ],
      "metadata": {
        "id": "3pcREeCPUn50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D CNN Without Tuner"
      ],
      "metadata": {
        "id": "TITm7tMnRkv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################ Without tuner ########################\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Activation, MaxPooling1D, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from kerastuner import RandomSearch\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.20, random_state=None, shuffle=True)\n",
        "xval, xtest, yval, ytest = train_test_split(xtest, ytest, test_size = 0.5, random_state=None, shuffle=True)\n",
        "\n",
        "def CNN_2D():\n",
        "    model = Sequential()\n",
        "\n",
        "    # layer 1\n",
        "    model.add(Conv2D(32, 4, 4, input_shape=(768, 23, 1), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(2))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "    # layer 2\n",
        "    model.add(Conv2D(16, 2, 2, activation=\"relu\"))\n",
        "    #model.add(MaxPooling2D(2))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "    # Flattening Layer:\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(96, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "\n",
        "    # Last Layer:\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr = 0.00002),\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "    return model\n",
        "\n",
        "model2 = CNN_2D()\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.0008, patience=40,  verbose=1, mode='min')\n",
        "\n",
        "history2_ = model2.fit(np.asarray(xtrain).reshape(len(np.asarray(xtrain)),768,23,1), utils.to_categorical(ytrain,2),\n",
        "                    validation_data=(np.asarray(xval).reshape(len(np.asarray(xval)),768,23,1), utils.to_categorical(yval,2)), callbacks = [stop_early],\n",
        "                    epochs=200, batch_size=150, verbose=1)\n"
      ],
      "metadata": {
        "id": "6-ItbbUTyZ8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(np.asarray(xtest).reshape(len(np.asarray(xtest)),768,23,1), utils.to_categorical(ytest,2))"
      ],
      "metadata": {
        "id": "7K1s35JDbq_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()\n",
        "plt.plot(history2_.history[\"accuracy\"])\n",
        "plt.plot(history2_.history[\"val_accuracy\"])\n",
        "plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "plt.ylabel(\"Accuracy\", fontsize = 15)\n",
        "plt.title(\"2D CNN Model Accuracy\", fontsize = 20)\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\",  prop={\"size\": 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(history2_.history[\"loss\"])\n",
        "plt.plot(history2_.history[\"val_loss\"])\n",
        "plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "plt.ylabel(\"Loss\", fontsize = 15)\n",
        "plt.title(\"2D CNN Model Loss\", fontsize = 20)\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\",  prop={\"size\": 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(model2.summary())\n",
        "\n",
        "plt.clf()\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cnn_predictions3 = model2.predict(np.asarray(xtest).reshape(len(np.asarray(xtest)),768,23,1))\n",
        "bert2_probs = cnn_predictions3[:,1]\n",
        "print(cnn_predictions3[:,1])\n",
        "cnn_predictions3 = np.argmax(cnn_predictions3, axis = 1)\n",
        "print(cnn_predictions3)\n",
        "confusion_matrix = confusion_matrix(ytest, cnn_predictions3)\n",
        "sns.heatmap(confusion_matrix, annot = True, fmt = \"d\", cbar = False)\n",
        "plt.title(\"BERT + 2D CNN + H. Tuning Confusion Matrix\", fontsize = 20)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "fpr_keras_bert_cnn2_hyp, tpr_keras_bert_cnn2_hyp, thresholds_keras = roc_curve(ytest, bert2_probs)\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "auc_keras_bert_cnn2_hyp = auc(fpr_keras_bert_cnn2_hyp, tpr_keras_bert_cnn2_hyp)\n",
        "print(\"AUC Score\", auc_keras_bert_cnn2_hyp)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras_bert_cnn2_hyp, tpr_keras_bert_cnn2_hyp, label=\"BERT + 2D-CNN: {:.3f}\".format(auc_keras_bert_cnn2_hyp))\n",
        "plt.xlabel(\"False positive rate\", fontsize = 15)\n",
        "plt.ylabel(\"True positive rate\", fontsize = 15)\n",
        "plt.title(\"ROC curve for BERT + 2D CNN\", fontsize = 20)\n",
        "plt.legend(loc=\"best\",  prop={'size': 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "precision_bert2, recall_bert2, _ = precision_recall_curve(ytest, bert2_probs)\n",
        "auc_precision_recall_bert2 = auc(recall_bert2, precision_bert2)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(recall_bert2, precision_bert2, label=\"BERT + 2D-CNN: {:.3f}\".format(auc_precision_recall_bert2))\n",
        "plt.xlabel(\"Recall\", fontsize = 15)\n",
        "plt.ylabel(\"Precision\", fontsize = 15)\n",
        "plt.title(\"PR curve for BERT + 2D CNN\", fontsize = 20)\n",
        "plt.legend(loc=\"best\",  prop={'size': 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------\")"
      ],
      "metadata": {
        "id": "UbikXZamiNuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D CNN with Tuner"
      ],
      "metadata": {
        "id": "dV8ypFSNRtxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################################## BERT + 2D CNN PART ############################################\n",
        "\n",
        "def build_model(hp):\n",
        "    # create model object\n",
        "    model = keras.Sequential([\n",
        "\n",
        "        # adding first convolutional layer\n",
        "        keras.layers.Conv2D(\n",
        "            # adding filter\n",
        "            filters=hp.Int('conv_1_filter', min_value=8, max_value=32, step=2),\n",
        "            # adding filter size or kernel size\n",
        "            kernel_size=hp.Choice('conv_1_kernel', values=[2, 6]),\n",
        "            # activation function\n",
        "            activation='relu',\n",
        "            input_shape=(768, 23, 1)),\n",
        "\n",
        "        # adding second convolutional layer\n",
        "        keras.layers.Conv2D(\n",
        "            # adding filter\n",
        "            filters=hp.Int('conv_2_filter', min_value=16, max_value=32, step=4),\n",
        "            # adding filter size or kernel size\n",
        "            kernel_size=hp.Choice('conv_2_kernel', values=[2, 8]),\n",
        "            # activation function\n",
        "            activation='relu'\n",
        "\n",
        "        ),\n",
        "\n",
        "        # adding flatten layer\n",
        "        keras.layers.Flatten(),\n",
        "        # adding dense layer\n",
        "        keras.layers.Dense(\n",
        "            units=hp.Int('dense_1_units', min_value=16, max_value=96, step=4),\n",
        "            activation='relu'\n",
        "        ),\n",
        "\n",
        "        # output layer\n",
        "        keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # compilation of model\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[0.00006, 0.00008, 0.0001])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "#importing random search\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "#creating randomsearch object\n",
        "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials = 20, directory = \"output\", project_name = \"Gly_AfterHyperParameterTuning_2D_CNN\")\n",
        "\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.20, random_state=None, shuffle=True)\n",
        "xval, xtest, yval, ytest = train_test_split(xtest, ytest, test_size = 0.5, random_state=None, shuffle=True)\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.0008, patience=40,  verbose=1, mode='min')\n",
        "\n",
        "tuner.search(np.asarray(xtrain).reshape(len(np.asarray(xtrain)),768,23,1), utils.to_categorical(ytrain,2),\n",
        "             validation_data = (np.asarray(xval.reshape(len(np.asarray(xval)),768,23,1)), utils.to_categorical(yval,2)), epochs = 30, callbacks = [stop_early])\n",
        "\n",
        "\n",
        "model_2D_ht = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "model_2D_ht.summary()\n",
        "\n",
        "history3 = model_2D_ht.fit(np.asarray(xtest).reshape(len(np.asarray(xtest)),768,23,1), utils.to_categorical(ytest,2),\n",
        "                           epochs=200, batch_size = 100, validation_split=0.1,\n",
        "                           initial_epoch=1)"
      ],
      "metadata": {
        "id": "X-cqr8VMCucQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history3.history[\"accuracy\"])\n",
        "plt.plot(history3.history[\"val_accuracy\"])\n",
        "plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "plt.ylabel(\"Accuracy\", fontsize = 15)\n",
        "plt.title(\"2D CNN Model Accuracy\", fontsize = 20)\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\",  prop={\"size\": 15})\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,10), dpi = 600)\n",
        "\n",
        "\n",
        "plt.plot(history3.history[\"loss\"])\n",
        "plt.plot(history3.history[\"val_loss\"])\n",
        "plt.xlabel(\"Epoch\", fontsize = 15)\n",
        "plt.ylabel(\"Loss\", fontsize = 15)\n",
        "plt.title(\"2D CNN Model Loss\", fontsize = 20)\n",
        "plt.legend([\"Train\", \"Test\"], loc=\"upper left\",  prop={\"size\": 15})\n",
        "plt.show()\n",
        "print(model_2D_ht.summary())\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cnn_predictions3 = model_2D_ht.predict(np.asarray(xtest).reshape(len(np.asarray(xtest)),768,23,1))\n",
        "bert2_probs = cnn_predictions3[:,1]\n",
        "print(cnn_predictions3[:,1])\n",
        "cnn_predictions3 = np.argmax(cnn_predictions3, axis = 1)\n",
        "print(cnn_predictions3)\n",
        "confusion_matrix = confusion_matrix(ytest, cnn_predictions3)\n",
        "sns.heatmap(confusion_matrix, annot = True, fmt = \"d\", cbar = False)\n",
        "plt.title(\"BERT + 2D CNN + H. Tuning Confusion Matrix\", fontsize = 20)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "print(cnn_predictions3)\n",
        "fpr_keras_bert_cnn2_hyp, tpr_keras_bert_cnn2_hyp, thresholds_keras = roc_curve(ytest, bert2_probs)\n",
        "\n",
        "from sklearn.metrics import auc\n",
        "auc_keras_bert_cnn2_hyp = auc(fpr_keras_bert_cnn2_hyp, tpr_keras_bert_cnn2_hyp)\n",
        "print(\"AUC Score\", auc_keras_bert_cnn2_hyp)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_keras_bert_cnn2_hyp, tpr_keras_bert_cnn2_hyp, label=\"BERT + 2D-CNN: {:.3f}\".format(auc_keras_bert_cnn2_hyp))\n",
        "plt.xlabel(\"False positive rate\", fontsize = 15)\n",
        "plt.ylabel(\"True positive rate\", fontsize = 15)\n",
        "plt.title(\"ROC curve for BERT + 2D CNN\", fontsize = 20)\n",
        "plt.legend(loc=\"best\",  prop={'size': 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------\")\n",
        "\n",
        "\n",
        "precision_bert2, recall_bert2, _ = precision_recall_curve(ytest, bert2_probs)\n",
        "auc_precision_recall_bert2 = auc(recall_bert2, precision_bert2)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(recall_bert2, precision_bert2, label=\"BERT + 2D-CNN: {:.3f}\".format(auc_precision_recall_bert2))\n",
        "plt.xlabel(\"Recall\", fontsize = 15)\n",
        "plt.ylabel(\"Precision\", fontsize = 15)\n",
        "plt.title(\"PR curve for BERT + 2D CNN\", fontsize = 20)\n",
        "plt.legend(loc=\"best\",  prop={'size': 15})\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------\")"
      ],
      "metadata": {
        "id": "49pLITNvrppr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ViT"
      ],
      "metadata": {
        "id": "JpLZXj4SRysv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv1D, ZeroPadding1D, MaxPooling1D, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from kerastuner import RandomSearch\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_addons as tfa\n",
        "import pickle\n",
        "import time\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "input_shape = (768, 23, 1)"
      ],
      "metadata": {
        "id": "jA9T5RUmSRsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 200\n",
        "num_epochs = 50\n",
        "image_size = 16\n",
        "patch_size = 6\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 12\n",
        "transformer_units = [projection_dim * 2, projection_dim, ]\n",
        "transformer_layers =  1\n",
        "mlp_head_units = [2048, 1024]"
      ],
      "metadata": {
        "id": "ZdPgGob9SYyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "#####  Use data augmentation\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(np.asarray(xtrain).reshape(len(np.asarray(xtrain)),768,23,1))"
      ],
      "metadata": {
        "id": "JVE4r0znSdxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######  Implement multilayer perceptron (MLP)\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "R4T2pZxkSjEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######  Implement patch creation as a layer\n",
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "QvEngQ_FSjHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######  Implement the patch encoding layer\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "INpW1JmgSjKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ################################ EDITTING VIT CODE #################################\n",
        "\n",
        "######  Build the ViT model\n",
        "\n",
        "def optimal_vit_classifier(hp):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    print(augmented.shape)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes, activation =\"softmax\")(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "\n",
        "\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate = learning_rate, weight_decay = weight_decay)\n",
        "\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[0.0005, 0.0001])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(),\n",
        "                           tf.keras.metrics.AUC(curve = \"ROC\"), tf.keras.metrics.AUC(curve = \"PR\")])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_ch = kt.RandomSearch(optimal_vit_classifier,\n",
        "                        objective=\"val_accuracy\",\n",
        "                        max_trials = 15, directory = \"output\", project_name = \"Gly_AfterHyperParameterTuning_ViT_homo\")\n"
      ],
      "metadata": {
        "id": "qvP7mawcSjNS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.0008, patience=100,  verbose=1, mode='min')\n",
        "\n",
        "tuner_ch.search(np.asarray(xtrain.reshape(len(np.asarray(xtrain)),768,23,1)), utils.to_categorical(ytrain,2),\n",
        "                validation_data = (np.asarray(xval.reshape(len(np.asarray(xval)),768,23,1)), utils.to_categorical(yval,2)), epochs = 50, callbacks = [stop_early])"
      ],
      "metadata": {
        "id": "q3Za5TdsSjST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tuner_ch.get_best_models(num_models=1)[0]\n",
        "history3_ = model3.fit(np.asarray(xtest).reshape(len(np.asarray(xtest)),768,23,1), utils.to_categorical(ytest,2), epochs = 700)"
      ],
      "metadata": {
        "id": "FzC7YL7BSjha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history3_.history)"
      ],
      "metadata": {
        "id": "sDYagx3uSjpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}