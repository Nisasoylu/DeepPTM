{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here, choose embeddings file:"
      ],
      "metadata": {
        "id": "L8Vl01mjX4SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.load(\"protbert_21_homo_ubi_cdhit_40_embeddings_X.npy\")\n",
        "#x = np.load(\"protbert_21_suc_suc_cdhit_40_embeddings_X.npy\")\n",
        "#x = np.load(\"protbert_21_mus_suc_cdhit_40_embeddings_X.npy\")\n",
        "#x = np.load(\"protbert_21_homo_suc_cdhit_40_embeddings_X.npy\")\n",
        "#x = np.load(\"protbert_21_homo_gly_cdhit_40_embeddings_X.npy\")\n",
        "#x = np.load(\"protbert_21_homo_crot_cdhit_40_embeddings_X.npy\")"
      ],
      "metadata": {
        "id": "XRmiQ7J0LIE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "nynTSqADLIR3",
        "outputId": "fe430c45-0dd2-47b8-edfe-8abf868487fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 23552)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, choose label file:"
      ],
      "metadata": {
        "id": "MCRZnurhYDjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.load(\"protbert_21_homo_ubi_cdhit_40_embeddings_Y.npy\")\n",
        "#y = np.load(\"protbert_21_suc_suc_cdhit_40_embeddings_Y.npy\")\n",
        "#y = np.load(\"protbert_21_mus_suc_cdhit_40_embeddings_Y.npy\")\n",
        "#y = np.load(\"protbert_21_homo_suc_cdhit_40_embeddings_Y.npy\")\n",
        "#y = np.load(\"protbert_21_homo_gly_cdhit_40_embeddings_Y.npy\")\n",
        "#y = np.load(\"protbert_21_homo_crot_cdhit_40_embeddings_Y.npy\")"
      ],
      "metadata": {
        "id": "LiqYjD-qLXB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-w9lGOkk_nA",
        "outputId": "140ce859-11e5-4b34-bfda-2b4f7bdca46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "x_dataframe = pd.DataFrame(x)"
      ],
      "metadata": {
        "id": "wkyDmq8Kyl2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "A7L45Ff2y_4f",
        "outputId": "730a9ae6-2785-44d6-bb38-cc3d5e8b1b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6      \\\n",
              "0     0.035548  0.135290  0.050323 -0.035690  0.155565  0.016983 -0.102318   \n",
              "1     0.054428  0.076421 -0.179935 -0.088075 -0.028636 -0.155652  0.024086   \n",
              "2    -0.027818  0.087484 -0.035493 -0.024342  0.167437 -0.083186 -0.098145   \n",
              "3     0.025916  0.020112 -0.152018 -0.076469  0.035116 -0.045748  0.020324   \n",
              "4     0.060541  0.027359  0.027861 -0.129359  0.169920 -0.037584 -0.067311   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3995 -0.004866 -0.039366 -0.116720 -0.072601 -0.039768 -0.030741 -0.096816   \n",
              "3996  0.090480  0.114564  0.044203 -0.073275  0.161670 -0.028918 -0.120396   \n",
              "3997  0.018428 -0.037868 -0.176185 -0.137686 -0.027452 -0.064239 -0.051554   \n",
              "3998  0.067468  0.116769  0.006776 -0.097331  0.190921 -0.017285 -0.105986   \n",
              "3999  0.018264 -0.026902 -0.177210 -0.161440  0.016296 -0.048195 -0.059184   \n",
              "\n",
              "         7         8         9      ...     23542     23543     23544  \\\n",
              "0     0.005895 -0.062817 -0.116456  ... -0.115739  0.039594 -0.039825   \n",
              "1    -0.170647  0.034186 -0.041658  ...  0.023030  0.023869  0.124658   \n",
              "2    -0.041637 -0.022276 -0.089738  ...  0.069424  0.017444 -0.073311   \n",
              "3    -0.076337  0.008275 -0.018836  ...  0.047788 -0.044167  0.061231   \n",
              "4     0.068669  0.048794 -0.102650  ...  0.047874 -0.049558 -0.045916   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3995 -0.033106  0.098819 -0.011633  ...  0.070767 -0.032568  0.026235   \n",
              "3996  0.017790 -0.023794 -0.069681  ...  0.005049 -0.026088 -0.047531   \n",
              "3997 -0.071545  0.072059  0.001733  ...  0.100576 -0.000563  0.121634   \n",
              "3998  0.042748 -0.047710 -0.101453  ...  0.007527 -0.003743 -0.048527   \n",
              "3999 -0.069409  0.082472  0.002426  ...  0.084648 -0.030719  0.083386   \n",
              "\n",
              "         23545     23546     23547     23548     23549     23550     23551  \n",
              "0    -0.159564  0.066614 -0.186917 -0.117691 -0.052009 -0.011152  0.006230  \n",
              "1    -0.190434  0.072021  0.085184 -0.107809  0.186227  0.135933  0.007104  \n",
              "2    -0.001961 -0.049592 -0.051528 -0.013668  0.026734 -0.003967  0.057242  \n",
              "3    -0.145769  0.062358 -0.016009 -0.146155  0.098747  0.069902 -0.063768  \n",
              "4    -0.010947  0.032469 -0.000465 -0.024339 -0.017838 -0.080384  0.048007  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "3995 -0.135301  0.037573  0.013667 -0.130521  0.099537  0.132984  0.004876  \n",
              "3996 -0.036480  0.026899 -0.015231  0.027820 -0.004362 -0.006736  0.093021  \n",
              "3997 -0.179653  0.066156  0.033876 -0.143835  0.141133  0.089987  0.022898  \n",
              "3998 -0.042418  0.026250 -0.022512  0.026978  0.001433  0.010297  0.095262  \n",
              "3999 -0.216920  0.052234  0.039744 -0.122938  0.087989  0.069953  0.043195  \n",
              "\n",
              "[4000 rows x 23552 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14fb1d51-1ff1-4998-9610-11ae91252200\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>23542</th>\n",
              "      <th>23543</th>\n",
              "      <th>23544</th>\n",
              "      <th>23545</th>\n",
              "      <th>23546</th>\n",
              "      <th>23547</th>\n",
              "      <th>23548</th>\n",
              "      <th>23549</th>\n",
              "      <th>23550</th>\n",
              "      <th>23551</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.035548</td>\n",
              "      <td>0.135290</td>\n",
              "      <td>0.050323</td>\n",
              "      <td>-0.035690</td>\n",
              "      <td>0.155565</td>\n",
              "      <td>0.016983</td>\n",
              "      <td>-0.102318</td>\n",
              "      <td>0.005895</td>\n",
              "      <td>-0.062817</td>\n",
              "      <td>-0.116456</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.115739</td>\n",
              "      <td>0.039594</td>\n",
              "      <td>-0.039825</td>\n",
              "      <td>-0.159564</td>\n",
              "      <td>0.066614</td>\n",
              "      <td>-0.186917</td>\n",
              "      <td>-0.117691</td>\n",
              "      <td>-0.052009</td>\n",
              "      <td>-0.011152</td>\n",
              "      <td>0.006230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.054428</td>\n",
              "      <td>0.076421</td>\n",
              "      <td>-0.179935</td>\n",
              "      <td>-0.088075</td>\n",
              "      <td>-0.028636</td>\n",
              "      <td>-0.155652</td>\n",
              "      <td>0.024086</td>\n",
              "      <td>-0.170647</td>\n",
              "      <td>0.034186</td>\n",
              "      <td>-0.041658</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023030</td>\n",
              "      <td>0.023869</td>\n",
              "      <td>0.124658</td>\n",
              "      <td>-0.190434</td>\n",
              "      <td>0.072021</td>\n",
              "      <td>0.085184</td>\n",
              "      <td>-0.107809</td>\n",
              "      <td>0.186227</td>\n",
              "      <td>0.135933</td>\n",
              "      <td>0.007104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.027818</td>\n",
              "      <td>0.087484</td>\n",
              "      <td>-0.035493</td>\n",
              "      <td>-0.024342</td>\n",
              "      <td>0.167437</td>\n",
              "      <td>-0.083186</td>\n",
              "      <td>-0.098145</td>\n",
              "      <td>-0.041637</td>\n",
              "      <td>-0.022276</td>\n",
              "      <td>-0.089738</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069424</td>\n",
              "      <td>0.017444</td>\n",
              "      <td>-0.073311</td>\n",
              "      <td>-0.001961</td>\n",
              "      <td>-0.049592</td>\n",
              "      <td>-0.051528</td>\n",
              "      <td>-0.013668</td>\n",
              "      <td>0.026734</td>\n",
              "      <td>-0.003967</td>\n",
              "      <td>0.057242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.025916</td>\n",
              "      <td>0.020112</td>\n",
              "      <td>-0.152018</td>\n",
              "      <td>-0.076469</td>\n",
              "      <td>0.035116</td>\n",
              "      <td>-0.045748</td>\n",
              "      <td>0.020324</td>\n",
              "      <td>-0.076337</td>\n",
              "      <td>0.008275</td>\n",
              "      <td>-0.018836</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047788</td>\n",
              "      <td>-0.044167</td>\n",
              "      <td>0.061231</td>\n",
              "      <td>-0.145769</td>\n",
              "      <td>0.062358</td>\n",
              "      <td>-0.016009</td>\n",
              "      <td>-0.146155</td>\n",
              "      <td>0.098747</td>\n",
              "      <td>0.069902</td>\n",
              "      <td>-0.063768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.060541</td>\n",
              "      <td>0.027359</td>\n",
              "      <td>0.027861</td>\n",
              "      <td>-0.129359</td>\n",
              "      <td>0.169920</td>\n",
              "      <td>-0.037584</td>\n",
              "      <td>-0.067311</td>\n",
              "      <td>0.068669</td>\n",
              "      <td>0.048794</td>\n",
              "      <td>-0.102650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047874</td>\n",
              "      <td>-0.049558</td>\n",
              "      <td>-0.045916</td>\n",
              "      <td>-0.010947</td>\n",
              "      <td>0.032469</td>\n",
              "      <td>-0.000465</td>\n",
              "      <td>-0.024339</td>\n",
              "      <td>-0.017838</td>\n",
              "      <td>-0.080384</td>\n",
              "      <td>0.048007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>-0.004866</td>\n",
              "      <td>-0.039366</td>\n",
              "      <td>-0.116720</td>\n",
              "      <td>-0.072601</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.030741</td>\n",
              "      <td>-0.096816</td>\n",
              "      <td>-0.033106</td>\n",
              "      <td>0.098819</td>\n",
              "      <td>-0.011633</td>\n",
              "      <td>...</td>\n",
              "      <td>0.070767</td>\n",
              "      <td>-0.032568</td>\n",
              "      <td>0.026235</td>\n",
              "      <td>-0.135301</td>\n",
              "      <td>0.037573</td>\n",
              "      <td>0.013667</td>\n",
              "      <td>-0.130521</td>\n",
              "      <td>0.099537</td>\n",
              "      <td>0.132984</td>\n",
              "      <td>0.004876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>0.090480</td>\n",
              "      <td>0.114564</td>\n",
              "      <td>0.044203</td>\n",
              "      <td>-0.073275</td>\n",
              "      <td>0.161670</td>\n",
              "      <td>-0.028918</td>\n",
              "      <td>-0.120396</td>\n",
              "      <td>0.017790</td>\n",
              "      <td>-0.023794</td>\n",
              "      <td>-0.069681</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005049</td>\n",
              "      <td>-0.026088</td>\n",
              "      <td>-0.047531</td>\n",
              "      <td>-0.036480</td>\n",
              "      <td>0.026899</td>\n",
              "      <td>-0.015231</td>\n",
              "      <td>0.027820</td>\n",
              "      <td>-0.004362</td>\n",
              "      <td>-0.006736</td>\n",
              "      <td>0.093021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>0.018428</td>\n",
              "      <td>-0.037868</td>\n",
              "      <td>-0.176185</td>\n",
              "      <td>-0.137686</td>\n",
              "      <td>-0.027452</td>\n",
              "      <td>-0.064239</td>\n",
              "      <td>-0.051554</td>\n",
              "      <td>-0.071545</td>\n",
              "      <td>0.072059</td>\n",
              "      <td>0.001733</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100576</td>\n",
              "      <td>-0.000563</td>\n",
              "      <td>0.121634</td>\n",
              "      <td>-0.179653</td>\n",
              "      <td>0.066156</td>\n",
              "      <td>0.033876</td>\n",
              "      <td>-0.143835</td>\n",
              "      <td>0.141133</td>\n",
              "      <td>0.089987</td>\n",
              "      <td>0.022898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>0.067468</td>\n",
              "      <td>0.116769</td>\n",
              "      <td>0.006776</td>\n",
              "      <td>-0.097331</td>\n",
              "      <td>0.190921</td>\n",
              "      <td>-0.017285</td>\n",
              "      <td>-0.105986</td>\n",
              "      <td>0.042748</td>\n",
              "      <td>-0.047710</td>\n",
              "      <td>-0.101453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007527</td>\n",
              "      <td>-0.003743</td>\n",
              "      <td>-0.048527</td>\n",
              "      <td>-0.042418</td>\n",
              "      <td>0.026250</td>\n",
              "      <td>-0.022512</td>\n",
              "      <td>0.026978</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.095262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>0.018264</td>\n",
              "      <td>-0.026902</td>\n",
              "      <td>-0.177210</td>\n",
              "      <td>-0.161440</td>\n",
              "      <td>0.016296</td>\n",
              "      <td>-0.048195</td>\n",
              "      <td>-0.059184</td>\n",
              "      <td>-0.069409</td>\n",
              "      <td>0.082472</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084648</td>\n",
              "      <td>-0.030719</td>\n",
              "      <td>0.083386</td>\n",
              "      <td>-0.216920</td>\n",
              "      <td>0.052234</td>\n",
              "      <td>0.039744</td>\n",
              "      <td>-0.122938</td>\n",
              "      <td>0.087989</td>\n",
              "      <td>0.069953</td>\n",
              "      <td>0.043195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 23552 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14fb1d51-1ff1-4998-9610-11ae91252200')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14fb1d51-1ff1-4998-9610-11ae91252200 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14fb1d51-1ff1-4998-9610-11ae91252200');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd3b4fcf-1438-46c8-b549-2ec778fa58c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd3b4fcf-1438-46c8-b549-2ec778fa58c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd3b4fcf-1438-46c8-b549-2ec778fa58c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJswL9-OzNhz",
        "outputId": "9a0c51d5-f1c2-44a4-97ab-1e2fb350b6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ViT"
      ],
      "metadata": {
        "id": "JpLZXj4SRysv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv1D, ZeroPadding1D, MaxPooling1D, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from kerastuner import RandomSearch\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_addons as tfa\n",
        "import pickle\n",
        "import time\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.20, random_state = 42)\n",
        "xval, xtest, yval, ytest = train_test_split(xtest, ytest, test_size = 0.5)\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "input_shape = (1024, 23, 1)"
      ],
      "metadata": {
        "id": "jA9T5RUmSRsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e565b2a1-2115-4c9d-cf10-c0e353c34c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-ab7d22d6a79a>:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner import RandomSearch\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 200\n",
        "num_epochs = 50\n",
        "image_size = 16\n",
        "patch_size = 6\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 12\n",
        "transformer_units = [projection_dim * 2, projection_dim, ]\n",
        "transformer_layers =  1\n",
        "mlp_head_units = [2048, 1024]"
      ],
      "metadata": {
        "id": "ZdPgGob9SYyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "#####  Use data augmentation\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(np.asarray(xtrain).reshape(len(np.asarray(xtrain)),1024,23,1))"
      ],
      "metadata": {
        "id": "JVE4r0znSdxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######  Implement multilayer perceptron (MLP)\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "R4T2pZxkSjEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######  Implement patch creation as a layer\n",
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "QvEngQ_FSjHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######  Implement the patch encoding layer\n",
        "\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "INpW1JmgSjKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######  Build the ViT model\n",
        "\n",
        "def optimal_vit_classifier(hp):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    print(augmented.shape)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes, activation =\"softmax\")(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "\n",
        "\n",
        "    optimizer = tfa.optimizers.AdamW(learning_rate = learning_rate, weight_decay = weight_decay)\n",
        "\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[0.0005, 0.0001])),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(),\n",
        "                           tf.keras.metrics.AUC(curve = \"ROC\"), tf.keras.metrics.AUC(curve = \"PR\")])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner_ch = kt.RandomSearch(optimal_vit_classifier,\n",
        "                        objective=\"val_accuracy\",\n",
        "                        max_trials = 20, directory = \"output\", project_name = \"Ubi_AfterHyperParameterTuning_ViT_homo_prot\")\n"
      ],
      "metadata": {
        "id": "qvP7mawcSjNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def36035-3615-43d4-8a07-5b8a6253b67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from output/Crot_AfterHyperParameterTuning_ViT_homo/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.0008, patience=100,  verbose=1, mode='min')\n",
        "\n",
        "tuner_ch.search(np.asarray(xtrain.reshape(len(np.asarray(xtrain)),1024,23,1)), utils.to_categorical(ytrain,2),\n",
        "                validation_data = (np.asarray(xval.reshape(len(np.asarray(xval)),1024,23,1)), utils.to_categorical(yval,2)), epochs = 100, callbacks = [stop_early])\n"
      ],
      "metadata": {
        "id": "q3Za5TdsSjST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tuner_ch.get_best_models(num_models=1)[0]\n",
        "history3_ = model3.fit(np.asarray(xtest).reshape(len(np.asarray(xtest)),1024,23,1), utils.to_categorical(ytest,2), epochs = 800)"
      ],
      "metadata": {
        "id": "FzC7YL7BSjha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}